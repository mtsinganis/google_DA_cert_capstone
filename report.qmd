---
title: "Case Study: How Does a Bike-Share Navigate Speedy Success?"
author: "Markos Tsinganis"
format: html
editor: visual
---

## 1. Ask

Financial analysts at Cyclistic have determined that customers that are annual members are more profitable than casual riders. The director of marketing believes future growth depends on maximizing the number of annual members. The overarching business task can be stated as follows:

**Business task**: Maximize the number of annual members by converting casual riders (single-ride and full-day passes) to annual members (annual membership).

In order to solve this business problem we need to design a new marketing strategy that will be informed by trends in the historical bike trip data. As a junior data analyst I have been asked to focus on one of the questions guiding the future marketing program:

**Data analysis goal**: How do annual members and casual riders use Cyclistic bikes differently?

### Key stakeholders

The key stakeholders in this project are:

-   **Cyclistic executive team**: They will decide whether to approve the recommended marketing program

-   **Lily Moreno (director of marketing)**: She is responsible for the development of campaigns and initiatives to promote the bike-share program and will need my recommendations to help her design a successful new marketing campaign to generate new annual memberships

## 2. Prepare

This fictional case involves Chicago-area bike ride share program [Divvy](https://divvybikes.com/). Divvy's [historical trip data](https://divvy-tripdata.s3.amazonaws.com/index.html) have been made available by Motivate International Inc. under this [license](https://ride.divvybikes.com/data-license-agreement), which includes the right to "access, reproduce, analyze, copy, modify, distribute in your product or service and use the Data for any lawful purpose".

The data is organized in a directory containing zipped `.csv` files. I will limit myself to the data from the previous 12 months (November 2021 - October 2022). The files in this time range use a consistent naming format ("YYYYMM-divvy-tripdata.zip"), making it easy to download the files programmatically. I use two R scripts to download the 12 `.zip` files corresponding to the 12-month period I will be focusing on. The scripts also extract the 12 `.csv` files of interest. These are placed in a sub-folder of the main directory called `raw_data`.

```{r load packages, output = FALSE}
# Loading required packages
library(dplyr)
library(here)
library(stringr)
library(tidyr)
library(readr)
library(ggplot2)
library(skimr)
```

I source the scripts `01_make_file_names_function.R` and `02_extract_csv_files.R` to programmatically download and extract the files. Once the 12 `.csv` files are extracted and saved in the newly created `raw_data` sub-folder I import them and save them as data frames in a list called `rides`:

```{r download-extract-import-csv-files}
#| cache: true

#source("01_make_file_names_function.R")
#source("02_extract_csv_files.R")

# create vector of .csv files to import
temp <- list.files(here("raw_data"), pattern="*.csv")

# import all .csv files as data frames and store them in a list called 'trips'
rides <- lapply(file.path(here("raw_data"), temp), read_csv,
                show_col_types = FALSE)

# extract date string from file names and name data frames (format 'yyyy_mm')
names(rides) <- sapply(temp, function(m) str_replace(m,
                                                pattern = "(.{4})(.{2})(.*)",
                                                replacement = paste("\\1_\\2")))
```

In order to start exploring the data and getting insights into the structure, I want to combine all data frames into one large data frame. Before I proceed, I need to confirm they have the same number of columns and identical column names.

```{r get-ncol-colnames}
sapply(rides, ncol)
sapply(lapply(rides, colnames), identical, colnames(rides[[1]]))
```

All data frames have 13 columns with identical column names. This allows me to combine them by row (stack them) in one large data frame.

```{r combine-dataframes}
#| cache: true

# bind all data frames of list by row (stack) and add new column 'yyyy_mm'
# linking each row to its original data frame
rides <- bind_rows(rides, .id = "yyyy_mm")
```

Let's take a look at the data frame to check how the data is organized:

```{r glimpse-data-frame}
# check the structure of 'trips'
glimpse(rides)
```

### Data bias and credibility

#### Bias

As far as I can ascertain, Divvy records all individual trips, independent of any customer attributes. This would suggest that the rides in my data set represent the entire population of rides, indicating an unbiased recording of rides.

#### Credibility

Let us look at different aspects of the credibility of the data.

-   **Reliable**: I consider the available data to be reliable in the sense that they are accurate (datetimes, locations, customer attributes recorder and measured accurately) and complete (all rides are recorded).
-   **Original**: The data is original since I am accessing data directly from the organization that collected it.
-   **Comprehensive**: The data set contains information that helps us answer our question. On the other hand, there is a lot more information that we could potentially have access to that would allow us to provide a more fine-grained view of the differences in usage between casual and annual riders (e.g. sex, home address, age). Due to data privacy issues however, personally identifiable information has been removed from the data set.
-   **Current**: The data I use in my analysis is current and represents the most recent information on the rides using Divvy's bikes.
-   **Cited**: The data comes directly from the company owning the bikes and is refreshed regularly, giving us confidence in the credibility of the data.

## 3. Process

In this section I do the following:

-   I decide on the tools I will use
-   I clean the data and document the cleaning process
-   I transform the data so that it is ready to analyze

### Choice of tool(s)

```{r}
#| echo: false
#| output: false
csv_size <- sum(sapply(list.files(here("raw_data"), full.names = TRUE),
                       file.size)) / 1024^3
object_size <- as.numeric(object.size(rides)) / 1024^3
my_ram <- parse_number(system2(command = 'systeminfo',
                               stdout = TRUE,
                               stderr = TRUE,
                               wait = TRUE)[25]) / 1024
```

The total size of the `.csv` files is `r round(csv_size, 2)` GiB and the size of the `rides` data frame is `r round(object_size, 3)` GiB, representing a relative increase of `r round((object_size - csv_size) / csv_size * 100, 2)`%. Despite the relatively large size of the object, it represents only a minor fraction (`r round(object_size / my_ram * 100, 2)`%) of the locally available RAM, well below the recommended 1/3 ratio. I therefore choose to use **RStudio** to process and analyze the data frame without the system crashing. Naturally, any duplication of such a large object or an increase in the number of columns may change these facts and may necessitate the use of an external database to pull data from as needed. I will reevaluate this decision once I start cleaning and transforming the data.

### Data cleaning

```{r}
# get broad overview of data frame with relevant summaries
skim_without_charts(rides)
```

I observe the following:

-   `yyyy_mm`: by design we have 12 unique months (November 2021 to December 2022)
-   `ride_id`: the unique values of `ride_id` are equal to the number of rows in the data frame. This is a confirmation that each of the `r nrow(rides)` rides (observations) in our data set is unique
-   `rideable_type`: this variable takes on three unique values (`r rides %>% distinct(rideable_type)`). It is not immediately clear what `docked_bike` means, given the fact that each observation represents a trip of length >60 sec.
-   `start_station_name` and `start_station_id`: these two variables have the exact same number of missing values (n = 878177), indicating that for any given observation, if one variable has a value the other one does too. Interestingly, the number of unique values of the two variables is **NOT** the same. There are 1639 values for `start_station_name` (excl. NAs) and 1306 values for `start_station_id`. In other words, there are some `start_station_id` values that correspond to multiple values of `start_station_name`. This is potentially problematic since it means that the station ids are not unique.



rides %>%
  group_by(start_station_name, start_station_id) %>%
    count() %>% 
     arrange(desc(start_station_name))

rides %>% summarize(n_distinct(start_station_id))

rides_small <- rides %>% select(start_station_name, start_station_id) %>% 
                           group_by(start_station_id)
rides_tiny <- rides %>% select(start_station_name, start_station_id) %>% 
                            group_by(start_station_id) %>% slice_sample(n = 200)
```{r}
df <- within(rides_small, {count <- ave(start_station_name, start_station_id,
                                 FUN=function(x) length(unique(x)))}) %>% 
    arrange(desc(count))
```

```{r}
df %>% 
    group_by(start_station_id, count) %>% 
    distinct(start_station_id, count) %>% 
    group_by(count) %>% 
    count()
    #ggplot(aes(x = count)) + geom_bar()
```
    
rides_small %>% count(name_na = is.na(start_station_id))

with(rides_small, {count <- ave(start_station_name, start_station_id,
                                FUN=function(x) length(unique(x)))})

test <- data.frame(x = letters[1:10], y = as.character(c(1:5, 5:9)))
test %>% group_by(x) %>% summarize(n_distinct(y))

rides_small %>%
  select(start_station_id) %>% 
      group_by(start_station_id) %>%
        count() %>%
          arrange(desc(n))


rides %>% group_by(yyyy_mm) %>% skim_without_charts
rides %>% mutate(missing = is.na(start_station_name)) %>% 
            group_by(missing) %>% skim_without_charts
rides %>% mutate(missing = is.na(start_station_name)) %>% 
            filter(missing == TRUE) %>% distinct(rideable_type)
rides %>% distinct(start_station_id) %>% top_n(10)

rides %>% mutate(missing = is.na(end_station_name)) %>% 
            group_by(missing) %>% skim_without_charts
When `start_station_name` is missing, there is only one `rideable_type` ("electric").
When `end_station_name` is missing, all three `rideable_type` categories are present.
When 

rides %>% group_by(yyyy_mm, rideable_type) %>%
          count() %>%
          arrange(yyyy_mm) %>% 
          ggplot(aes(x = yyyy_mm, y = n, fill = rideable_type)) +
          geom_bar(position="dodge", stat="identity") +
          theme(axis.text.x = element_text(angle = 90))

rides %>% group_by()

### Data transformation

## 4. Analyze

**knitr::opts_chunk\$set(fig.path = here::here("figs"))**

## 5. Share

## 6. Act
