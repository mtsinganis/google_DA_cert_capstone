---
title: "Case Study: How Does a Bike-Share Navigate Speedy Success?"
author: "Markos Tsinganis"
format: html
editor: visual
---

## 1. Ask

Financial analysts at Cyclistic have determined that annual members are more profitable than casual riders. The director of marketing believes future growth depends on maximizing the number of annual members. The overarching business task can be stated as follows:

**Business task**: Maximize the number of annual members by converting casual riders (single-ride and full-day passes) to annual members (annual membership).

In order to solve this business problem we need to design a new marketing strategy that will be informed by trends in the historical bike trip data. As a junior data analyst I have been asked to focus on one of the questions guiding the future marketing program:

**Data analysis goal**: How do annual members and casual riders use Cyclistic bikes differently?

### Key stakeholders

The key stakeholders in this project are:

-   **Cyclistic executive team**: They will decide whether to approve the recommended marketing program

-   **Lily Moreno (director of marketing and my manager)**: She is responsible for the development of campaigns and initiatives to promote the bike-share program and will need my recommendations to help her design a successful new marketing campaign to generate new annual memberships

## 2. Prepare

This fictional case involves Chicago-area bike ride share program [Divvy](https://divvybikes.com/). Divvy's [historical trip data](https://divvy-tripdata.s3.amazonaws.com/index.html) have been made available by Motivate International Inc. under this [license](https://ride.divvybikes.com/data-license-agreement), which includes the right to "access, reproduce, analyze, copy, modify, distribute in your product or service and use the Data for any lawful purpose".

The data is organized in a directory containing zipped `.csv` files. Based on the file names I can deduce that they cover the period from 2013 to 2022. I will limit myself to the data from the most recent 12 months available (November 2021 - October 2022). The files in this time range use a consistent naming format ('YYYYMM-divvy-tripdata.zip'), making it easy to download the files programmatically. I use two R scripts to download the 12 `.zip` files and extract the 12 `.csv` files of interest. These are placed in a sub-folder of the main directory called `raw_data`.

Loading required packages:

```{r load packages, output = FALSE}
library(dplyr)
suppressPackageStartupMessages(library(here))
library(stringr)
library(tidyr)
library(readr)
library(ggplot2)
```

I source the scripts `01_make_file_names_function.R` and `02_extract_csv_files.R` to programmatically download and extract the files:

```{r source-scripts-to-download-and-extract-csv-files}
#source("01_make_file_names_function.R")
#source("02_extract_csv_files.R")
```

Once the 12 `.csv` files are extracted and saved in the `raw_data` sub-folder I import them as data frames and save them in a list:

```{r import data, cache = TRUE}
# create vector of .csv files to import
temp <- list.files(here("raw_data"), pattern="*.csv")

# import all .csv files as data frames and store them in a list called 'trips'
trips <- lapply(file.path(here("raw_data"), temp), read_csv)

# extract date from file names and name data frames in the format 'yyyy_mm'
names(trips) <- sapply(temp, function(m) str_replace(m,
                                                pattern = "(.{4})(.{2})(.*)",
                                                replacement = paste("\\1_\\2")))

# get a glimpse of the list
glimpse(trips[1:2])
```

Before I combine all the data frames into one, I need to confirm whether they have same number of columns and identical column names.

```{r get-number-of-columns}
sapply(trips, ncol)
```
All data frames have 13 columns.

```{r check-if-same-column-names}
sapply(lapply(trips, colnames), identical, colnames(trips[[1]]))
```
They also have identical column names. This allows me to combine them (stack them) by row in one large data frame.

```{r combine-dataframes, cache = TRUE}
# bind all data frames of list by row (stack) and add new column 'yyyy_mm'
# linking each row to its original data frame
trips <- bind_rows(trips, .id = "yyyy_mm")
```

```{r separate-yyyy_mm-column, cache = TRUE}
# separate 'yyyy_mm' column into 'year' and 'month' columns
trips <- trips %>% 
           separate(yyyy_mm,
                    into = c("year", "month"),
                    sep = "_",
                    remove = FALSE,
                    convert = TRUE)
```

I now check how many bike trips were registered per month.

```{r plot-trips-per-month}
trips %>%
    group_by(yyyy_mm) %>% 
    summarise(n = n()) %>% 
    ggplot(aes(x = yyyy_mm, y = n, group = 1)) + geom_line(color = "blue") +
    theme(axis.text.x = element_text(angle = 90))

```
The number of bike trips shows clear seasonality, with a peak in July and a trough in January, suggesting bike usage is highly dependent on general weather conditions.





A brief look at the file sizes suggests that importing these into RStudio and combining them in one dataframe can potentially crash the program or slow it down considerably. I therefore choose to avoid importing all the data in RStudio, but instead download the .csv files in my computer and save them as separate tables in a new SQLite database. I then use R to send SQL queries to the database to retrieve only the data I need for a particular analysis.

```{r plot .csv file sizes by month}
# csv_sizes <- tibble(file = list.files(here("raw_data")),
#                     size = file.size(list.files(here("raw_data"),
#                                                 full.names = TRUE))) %>% 
#                mutate(size_mb = size / 1048576)
# 
# library(ggplot2)
# library(stringr)
# 
# my_labels <- sapply(csv_sizes$file, function(m) str_replace(m,
#                                                 pattern = "(.{4})(.{2})(.*)",
#                                                 replacement = paste("\\1-\\2")))
# 
# csv_sizes %>% 
#     ggplot(aes(x = file, y = size_mb, group = 1)) + geom_line() +
#     labs(title = paste0("Total size of files is ",
#                         csv_sizes %>% summarize(round(sum(size_mb), 0)) %>% 
#                             pull(), " MB")) +
#     theme(axis.text.x = element_text(angle = 45)) +
#     scale_x_discrete(labels = my_labels)


```

## 3. Process

## 4. Analyze

**knitr::opts_chunk\$set(fig.path = here::here("figs"))**

## 5. Share

## 6. Act
